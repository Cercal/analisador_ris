import os
import glob
import re
import unicodedata
import pandas as pd
from collections import Counter
import csv

def normalizar_texto(texto):
    """
    Normaliza o texto removendo acentos, convertendo para minÃºsculas
    e removendo caracteres especiais
    """
    if not texto:
        return ""
    
    # Remove acentos
    texto = unicodedata.normalize('NFKD', str(texto))
    texto = ''.join([c for c in texto if not unicodedata.combining(c)])
    
    # Converte para minÃºsculas
    texto = texto.lower()
    
    # Remove caracteres especiais, mantendo apenas letras, nÃºmeros e espaÃ§os
    texto = re.sub(r'[^a-z0-9\s]', ' ', texto)
    
    # Remove espaÃ§os extras
    texto = ' '.join(texto.split())
    
    return texto

def parse_ris_file(file_path):
    """
    FunÃ§Ã£o para ler e parsear um arquivo .RIS
    Retorna uma lista de dicionÃ¡rios, onde cada dicionÃ¡rio Ã© um registro
    """
    registros = []
    registro_atual = {}
    
    try:
        # Tenta diferentes codificaÃ§Ãµes
        codificacoes = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
        linhas = None
        
        for encoding in codificacoes:
            try:
                with open(file_path, 'r', encoding=encoding) as file:
                    linhas = file.readlines()
                break
            except UnicodeDecodeError:
                continue
        
        if linhas is None:
            print(f"  âŒ Erro de codificaÃ§Ã£o no arquivo: {os.path.basename(file_path)}")
            return []
            
    except Exception as e:
        print(f"  âŒ Erro ao ler arquivo {file_path}: {e}")
        return []
    
    for linha in linhas:
        linha = linha.strip()
        
        # Fim do registro
        if linha == 'ER  -':
            if registro_atual:
                registros.append(registro_atual)
                registro_atual = {}
        
        # Campo RIS (formato: "XX  - valor")
        elif len(linha) >= 6 and linha[2:4] == '  -':
            campo = linha[0:2].strip()
            valor = linha[6:].strip()
            
            # Para campos que podem ter mÃºltiplos valores (AU, KW), armazena como lista
            if campo in ['AU', 'KW']:
                if campo not in registro_atual:
                    registro_atual[campo] = []
                registro_atual[campo].append(valor)
            else:
                registro_atual[campo] = valor
    
    # NÃ£o esquecer o Ãºltimo registro se nÃ£o terminou com ER
    if registro_atual:
        registros.append(registro_atual)
    
    return registros

def determinar_tipo_item(registro):
    """
    Determina o tipo do item baseado no campo TY e M3
    """
    tipo = registro.get('TY', 'Desconhecido')
    
    if tipo == 'THES':
        # Para teses, pega o tipo do campo M3
        return registro.get('M3', 'Tese nÃ£o especificada')
    elif tipo == 'JOUR':
        return 'Artigo de PeriÃ³dico'
    elif tipo == 'BOOK':
        return 'Livro'
    elif tipo == 'CHAP':
        return 'CapÃ­tulo de Livro'
    elif tipo == 'CONF':
        return 'ConferÃªncia'
    else:
        return tipo

def determinar_fonte(registro):
    """
    Determina a fonte/periÃ³dico baseado no tipo
    """
    tipo = registro.get('TY', '')
    
    if tipo == 'JOUR':
        return registro.get('T2', registro.get('JO', 'PeriÃ³dico nÃ£o especificado'))
    elif tipo == 'THES':
        return registro.get('PB', 'Universidade nÃ£o especificada')
    else:
        return registro.get('PB', registro.get('T2', 'Fonte nÃ£o especificada'))

def contar_palavras_chave_especificas(texto, palavras_chave):
    """
    Conta a ocorrÃªncia de palavras-chave especÃ­ficas em um texto
    """
    if not texto:
        return {}
    
    texto_normalizado = normalizar_texto(texto)
    contagem = {}
    
    for palavra in palavras_chave:
        palavra_normalizada = normalizar_texto(palavra)
        # Conta ocorrÃªncias (case insensitive e sem acentos)
        contagem[palavra] = texto_normalizado.count(palavra_normalizada)
    
    return contagem

def processar_ris_estatisticas(pasta_entrada):
    """
    Processa todos os arquivos .RIS e gera estatÃ­sticas completas
    """
    # Lista de palavras-chave especÃ­ficas para busca
    PALAVRAS_CHAVE_ESPECIFICAS = [
        "lixo eletrÃ´nico",
        "resÃ­duo eletrÃ´nico", 
        "resÃ­duos eletrÃ´nicos",
        "resÃ­duos de equipamentos elÃ©tricos e eletrÃ´nicos",
        "REEE",
        "lixo eletroeletrÃ´nico",
        "resÃ­duo eletroeletrÃ´nico",
        "resÃ­duos eletroeletrÃ´nicos",
        "e-waste",
        "electronic waste",
        "waste electrical and electronic equipment",
        "WEEE",
        "basura electrÃ³nica",
        "residuo electrÃ³nico",
        "residuos electrÃ³nicos",
        "residuos de aparatos elÃ©ctricos y electrÃ³nicos",
        "REEE"
    ]
    
    # Encontrar todos os arquivos .ris na pasta
    arquivos_ris = glob.glob(os.path.join(pasta_entrada, "*.ris"))
    
    if not arquivos_ris:
        print("âŒ Nenhum arquivo .ris encontrado na pasta especificada.")
        return
    
    print(f"ğŸ“ Encontrados {len(arquivos_ris)} arquivo(s) .ris")
    
    # Estruturas para armazenar estatÃ­sticas
    todos_registros = []
    contagem_tipos = Counter()
    contagem_autores = Counter()
    contagem_anos = Counter()
    contagem_idiomas = Counter()
    contagem_fontes = Counter()
    todas_palavras_chave = Counter()
    contagem_palavras_especificas_kw = Counter()
    contagem_palavras_especificas_ab = Counter()
    
    # Processar cada arquivo
    for arquivo_ris in arquivos_ris:
        print(f"ğŸ” Processando: {os.path.basename(arquivo_ris)}")
        
        registros = parse_ris_file(arquivo_ris)
        todos_registros.extend(registros)
        
        print(f"  âœ… {len(registros)} registros processados")
    
    # Processar estatÃ­sticas
    for registro in todos_registros:
        # Tipo de item
        tipo = determinar_tipo_item(registro)
        contagem_tipos[tipo] += 1
        
        # Autores
        autores = registro.get('AU', [])
        if isinstance(autores, list):
            for autor in autores:
                if autor:  # Remove autores vazios
                    contagem_autores[autor] += 1
        elif autores:  # Se for string Ãºnica
            contagem_autores[autores] += 1
        
        # Ano de publicaÃ§Ã£o
        ano = registro.get('PY', 'Ano nÃ£o especificado')
        contagem_anos[ano] += 1
        
        # Idioma
        idioma = registro.get('LA', 'Idioma nÃ£o especificado')
        contagem_idiomas[idioma] += 1
        
        # Fonte/PeriÃ³dico
        fonte = determinar_fonte(registro)
        contagem_fontes[fonte] += 1
        
        # Palavras-chave gerais
        keywords = registro.get('KW', [])
        if isinstance(keywords, list):
            for kw in keywords:
                if kw:
                    kw_normalizada = normalizar_texto(kw)
                    todas_palavras_chave[kw_normalizada] += 1
                    
                    # Contar palavras-chave especÃ­ficas em KW
                    contagem_kw = contar_palavras_chave_especificas(kw, PALAVRAS_CHAVE_ESPECIFICAS)
                    for palavra, count in contagem_kw.items():
                        if count > 0:
                            contagem_palavras_especificas_kw[palavra] += count
        elif keywords:
            kw_normalizada = normalizar_texto(keywords)
            todas_palavras_chave[kw_normalizada] += 1
            contagem_kw = contar_palavras_chave_especificas(keywords, PALAVRAS_CHAVE_ESPECIFICAS)
            for palavra, count in contagem_kw.items():
                if count > 0:
                    contagem_palavras_especificas_kw[palavra] += count
        
        # Palavras-chave especÃ­ficas no resumo
        abstract = registro.get('AB', '')
        if abstract:
            contagem_ab = contar_palavras_chave_especificas(abstract, PALAVRAS_CHAVE_ESPECIFICAS)
            for palavra, count in contagem_ab.items():
                if count > 0:
                    contagem_palavras_especificas_ab[palavra] += count
    
    # Gerar relatÃ³rios
    print(f"\n{'='*60}")
    print("ğŸ“Š RELATÃ“RIO COMPLETO DE ANÃLISE .RIS")
    print(f"{'='*60}")
    
    # 1. Tipo de Itens
    print(f"\nğŸ“‹ TIPOS DE ITENS ({len(contagem_tipos)} tipos encontrados):")
    for tipo, count in contagem_tipos.most_common():
        print(f"   â€¢ {tipo}: {count} ocorrÃªncias")
    
    # 2. Autores
    print(f"\nğŸ‘¥ AUTORES (Top 20 de {len(contagem_autores)} autores):")
    for autor, count in contagem_autores.most_common(20):
        print(f"   â€¢ {autor}: {count} publicaÃ§Ã£o(Ãµes)")
    
    # 3. PublicaÃ§Ãµes por Ano
    print(f"\nğŸ“… PUBLICAÃ‡Ã•ES POR ANO ({len(contagem_anos)} anos):")
    for ano, count in sorted(contagem_anos.items()):
        print(f"   â€¢ {ano}: {count} publicaÃ§Ã£o(Ãµes)")
    
    # 4. PublicaÃ§Ãµes por Idioma
    print(f"\nğŸŒ PUBLICAÃ‡Ã•ES POR IDIOMA ({len(contagem_idiomas)} idiomas):")
    for idioma, count in contagem_idiomas.most_common():
        print(f"   â€¢ {idioma}: {count} publicaÃ§Ã£o(Ãµes)")
    
    # 5. PublicaÃ§Ãµes por PeriÃ³dico/Base
    print(f"\nğŸ“š PUBLICAÃ‡Ã•ES POR FONTE (Top 20 de {len(contagem_fontes)} fontes):")
    for fonte, count in contagem_fontes.most_common(20):
        print(f"   â€¢ {fonte}: {count} publicaÃ§Ã£o(Ãµes)")
    
    # 6. Palavras-chave Gerais
    print(f"\nğŸ”¤ PALAVRAS-CHAVE GERAIS (Top 30 de {len(todas_palavras_chave)} palavras):")
    for palavra, count in todas_palavras_chave.most_common(30):
        print(f"   â€¢ {palavra}: {count} ocorrÃªncia(s)")
    
    # 7. Palavras-chave EspecÃ­ficas em KW
    print(f"\nğŸ¯ PALAVRAS-CHAVE ESPECÃFICAS EM CAMPO KW:")
    for palavra, count in contagem_palavras_especificas_kw.most_common():
        if count > 0:
            print(f"   â€¢ {palavra}: {count} ocorrÃªncia(s)")
    
    # 8. Palavras-chave EspecÃ­ficas em AB
    print(f"\nğŸ“ PALAVRAS-CHAVE ESPECÃFICAS EM RESUMOS (AB):")
    for palavra, count in contagem_palavras_especificas_ab.most_common():
        if count > 0:
            print(f"   â€¢ {palavra}: {count} ocorrÃªncia(s)")
    
    # Exportar para CSV ÃšNICO
    exportar_para_csv_unico(
        contagem_tipos, contagem_autores, contagem_anos, 
        contagem_idiomas, contagem_fontes, todas_palavras_chave,
        contagem_palavras_especificas_kw, contagem_palavras_especificas_ab,
        pasta_entrada, len(todos_registros)
    )
    
    return {
        'total_registros': len(todos_registros),
        'tipos': dict(contagem_tipos),
        'autores': dict(contagem_autores),
        'anos': dict(contagem_anos),
        'idiomas': dict(contagem_idiomas),
        'fontes': dict(contagem_fontes),
        'palavras_chave_gerais': dict(todas_palavras_chave),
        'palavras_especificas_kw': dict(contagem_palavras_especificas_kw),
        'palavras_especificas_ab': dict(contagem_palavras_especificas_ab)
    }

def exportar_para_csv_unico(contagem_tipos, contagem_autores, contagem_anos, 
                           contagem_idiomas, contagem_fontes, todas_palavras_chave,
                           contagem_palavras_especificas_kw, contagem_palavras_especificas_ab,
                           pasta_entrada, total_registros):
    """
    Exporta todas as estatÃ­sticas para um Ãºnico arquivo CSV
    """
    # Criar DataFrame Ãºnico
    dados_completos = []
    
    # 1. Metadados bÃ¡sicos
    dados_completos.append({
        'Categoria': 'METADADOS',
        'Item': 'Total de Registros Processados',
        'Quantidade': total_registros,
        'Detalhes': ''
    })
    
    # 2. Tipos de Itens
    dados_completos.append({
        'Categoria': 'TIPOS DE ITENS',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'Total de {len(contagem_tipos)} tipos encontrados'
    })
    for tipo, count in contagem_tipos.most_common():
        dados_completos.append({
            'Categoria': 'TIPOS DE ITENS',
            'Item': tipo,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 3. Autores (Top 50)
    dados_completos.append({
        'Categoria': 'AUTORES',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'Top 50 de {len(contagem_autores)} autores encontrados'
    })
    for autor, count in contagem_autores.most_common(50):
        dados_completos.append({
            'Categoria': 'AUTORES',
            'Item': autor,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 4. PublicaÃ§Ãµes por Ano
    dados_completos.append({
        'Categoria': 'PUBLICAÃ‡Ã•ES POR ANO',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'DistribuiÃ§Ã£o em {len(contagem_anos)} anos'
    })
    for ano, count in sorted(contagem_anos.items()):
        dados_completos.append({
            'Categoria': 'PUBLICAÃ‡Ã•ES POR ANO',
            'Item': ano,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 5. PublicaÃ§Ãµes por Idioma
    dados_completos.append({
        'Categoria': 'PUBLICAÃ‡Ã•ES POR IDIOMA',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'Total de {len(contagem_idiomas)} idiomas'
    })
    for idioma, count in contagem_idiomas.most_common():
        dados_completos.append({
            'Categoria': 'PUBLICAÃ‡Ã•ES POR IDIOMA',
            'Item': idioma,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 6. PublicaÃ§Ãµes por Fonte
    dados_completos.append({
        'Categoria': 'PUBLICAÃ‡Ã•ES POR FONTE',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'Top 30 de {len(contagem_fontes)} fontes encontradas'
    })
    for fonte, count in contagem_fontes.most_common(30):
        dados_completos.append({
            'Categoria': 'PUBLICAÃ‡Ã•ES POR FONTE',
            'Item': fonte,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 7. Palavras-chave Gerais (Top 50)
    dados_completos.append({
        'Categoria': 'PALAVRAS-CHAVE GERAIS',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': f'Top 50 de {len(todas_palavras_chave)} palavras-chave'
    })
    for palavra, count in todas_palavras_chave.most_common(50):
        dados_completos.append({
            'Categoria': 'PALAVRAS-CHAVE GERAIS',
            'Item': palavra,
            'Quantidade': count,
            'Detalhes': ''
        })
    
    # 8. Palavras-chave EspecÃ­ficas em KW
    dados_completos.append({
        'Categoria': 'PALAVRAS-CHAVE ESPECÃFICAS (KW)',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': 'OcorrÃªncias das palavras-alvo no campo de palavras-chave'
    })
    for palavra, count in contagem_palavras_especificas_kw.most_common():
        if count > 0:
            dados_completos.append({
                'Categoria': 'PALAVRAS-CHAVE ESPECÃFICAS (KW)',
                'Item': palavra,
                'Quantidade': count,
                'Detalhes': ''
            })
    
    # 9. Palavras-chave EspecÃ­ficas em AB
    dados_completos.append({
        'Categoria': 'PALAVRAS-CHAVE ESPECÃFICAS (AB)',
        'Item': '---',
        'Quantidade': '',
        'Detalhes': 'OcorrÃªncias das palavras-alvo nos resumos'
    })
    for palavra, count in contagem_palavras_especificas_ab.most_common():
        if count > 0:
            dados_completos.append({
                'Categoria': 'PALAVRAS-CHAVE ESPECÃFICAS (AB)',
                'Item': palavra,
                'Quantidade': count,
                'Detalhes': ''
            })
    
    # Criar DataFrame e exportar
    df = pd.DataFrame(dados_completos)
    
    # Nome do arquivo de saÃ­da
    arquivo_saida = os.path.join(pasta_entrada, "estatisticas_completas_ris.csv")
    
    # Exportar para CSV
    df.to_csv(arquivo_saida, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ’¾ Arquivo CSV Ãºnico exportado: {arquivo_saida}")
    print(f"   â€¢ Total de linhas: {len(df)}")
    print(f"   â€¢ Categorias incluÃ­das: 9")
    print(f"   â€¢ Formato: Categoria, Item, Quantidade, Detalhes")

def main():
    """
    FunÃ§Ã£o principal
    """
    print("ğŸ” ANALISADOR DE ARQUIVOS .RIS - CSV ÃšNICO")
    print("=" * 50)
    
    # Obter caminho da pasta
    pasta_entrada = input("Digite o caminho da pasta com os arquivos .ris: ").strip().strip('"')
    
    if not os.path.exists(pasta_entrada):
        print("âŒ Pasta nÃ£o encontrada!")
        return
    
    # Processar estatÃ­sticas
    estatisticas = processar_ris_estatisticas(pasta_entrada)
    
    if estatisticas:
        print(f"\nğŸ‰ ANÃLISE CONCLUÃDA COM SUCESSSO!")
        print(f"ğŸ“Š Total de registros processados: {estatisticas['total_registros']}")
        print(f"ğŸ’¾ Arquivo Ãºnico gerado: estatisticas_completas_ris.csv")

if __name__ == "__main__":
    main()
